# Class 19 â€“ Introduction to Machine Learning  

## ğŸ“– A Glimpse into the Past  

### Early Foundations  
- **1943 â€“ Neural Network Model**  
  Walter Pitts and Warren McCulloch introduced the first mathematical model of a neural network, inspired by the structure of the human brain.  
  - Demonstrated how artificial neurons could process simple logical operations.  

- **1952 â€“ Term "Machine Learning" Coined**  
  Arthur Samuel created a checkers-playing program that **learned from experience**.  
  - Instead of relying on fixed instructions, the program improved its strategy after each game.  

- **1957 â€“ The Perceptron**  
  Frank Rosenblatt designed the **Perceptron**, an early neural network for image recognition.  
  - One of the first practical ML systems capable of **learning to classify patterns**.  

---

## âš–ï¸ Traditional Programming vs. Machine Learning  

### Traditional Programming  
- Based on **explicit, fixed rules**.  
- Every decision is hard-coded.  
- Cannot adapt to new/unforeseen situations.  
- Requires human updates for new cases.  
- Analogy â†’ Following a **recipe** step by step.  

### Machine Learning  
- Learns directly from **data**.  
- Finds **patterns** and builds rules on its own.  
- Adapts to new situations.  
- Improves over time with more data.  
- Analogy â†’ Learning to cook by **tasting and adjusting**.  

---

## ğŸ”‘ Types of Machine Learning  

1. **Supervised Learning**  
   - Trains on labeled data (inputs + outputs known).  
   - Goal: predict unseen outputs.  
   - **Examples:**  
     - Fraud detection in banking.  
     - Spam email filtering.  
     - Medical diagnosis from patient data.  

2. **Unsupervised Learning**  
   - Works on unlabeled data.  
   - Goal: find hidden **patterns or clusters**.  
   - **Examples:**  
     - Customer segmentation in retail.  
     - Anomaly detection in cybersecurity.  
     - Market basket analysis in e-commerce.  

3. **Reinforcement Learning (RL)**  
   - Agent interacts with an environment.  
   - Learns by **rewards (positive)** and **penalties (negative)**.  
   - **Examples:**  
     - Robotics & autonomous navigation.  
     - AlphaGo / Chess-playing AI.  
     - Personalized recommendation engines.  

4. **Semi-Supervised Learning**  
   - Combines small labeled datasets + large unlabeled datasets.  
   - Useful when labeling is costly/time-consuming.  
   - Common in **medical imaging** and **NLP tasks**.  

---

## ğŸ—ï¸ Machine Learning Models  

- **Regression Models**  
  - Predict continuous values.  
  - Example: house price prediction, stock forecasting.  

- **Classification Models**  
  - Assign inputs into discrete categories.  
  - Example: cancer detection (benign vs malignant).  

- **Clustering Models**  
  - Group similar items without labels.  
  - Example: customer segmentation.  

- **Deep Learning Models**  
  - Neural networks with many layers.  
  - Specialize in image, text, and speech tasks.  
  - Drive modern AI advances like **NLP, self-driving cars, and computer vision**.  

---

## ğŸ“Š Real-World Applications of ML  

- **Healthcare** â†’ Medical image analysis, drug discovery, patient risk prediction.  
- **Finance** â†’ Fraud detection, credit scoring, algorithmic trading.  
- **Retail** â†’ Personalized recommendations, inventory management.  
- **Transportation** â†’ Self-driving cars, traffic prediction, logistics optimization.  
- **Media & Entertainment** â†’ Content recommendation (YouTube, Netflix, Spotify).  

---

## ğŸ§  Key Takeaways  

- ML shifts from **hard-coded instructions â†’ data-driven learning**.  
- Different ML paradigms (supervised, unsupervised, RL, semi-supervised) fit different use cases.  
- Applications span nearly every modern industry.  
- **Deep Learning** is a subset of ML, powering breakthroughs in vision, speech, and natural language processing.  

